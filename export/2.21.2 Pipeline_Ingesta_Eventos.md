---
id: 2.21.2
title: Pipeline Ingesta Eventos
parent: '2.21'
breadcrumb: 0 → 2.0 → 2.21 → 2.21.2
type: arquitectura
status: futuro
domain:
- etl
- pipeline
- airbyte
- events
summary: Mecanismos para capturar y transportar datos desde la App y DB operativa
  al Warehouse.
last_updated: 2026-01-29 15:32
content_hash: 548408b14165bdc8
---

# 2.21.2 Pipeline Ingesta Eventos

> **[FUTURO]** Las "tuberías" que mueven los datos de forma confiable.

---

## Fuentes de Datos (Sources)

1.  **Base de Datos Operativa (Supabase):** Datos "fríos" y estructurados (Usuarios, Órdenes).
2.  **Telemetry App (Clickstream):** Datos "calientes" y voluminosos (Clicks, Scrolls, Vistas).
3.  **Terceros:** Stripe (Finanzas), Zendesk/Chat (Soporte).

---

## Herramientas de Ingesta

### Airbyte (EL)
Utilizamos Airbyte (Self-hosted o Cloud) para sincronizar Supabase -> Warehouse cada X horas.
*   **Modo:** Incremental Append (Solo trae lo nuevo).
*   **CDC (Change Data Capture):** Leer el WAL de Postgres para replicación casi real-time.

### Event Collector
Para telemetría de la App, no escribir directo a DB.
*   **Track:** `analytics.track('Solicitud Creada', { precio: 500 })`.
*   **Buffer:** Los eventos van a una cola (Redis/Kafka) antes de insertarse en batch al Warehouse.

---

## Transformación (T) - dbt
Una vez los datos están en el Warehouse (Raw), usamos **dbt (data build tool)** para limpiarlos y crear las tablas finales listas para el dashboard.
*   *Raw:* `public.users`
*   *Clean:* `analytics.dim_users` (Sin passwords, emails normalizados).

---

## Navegación

| ⬆️ Padre             | [[Proyecto OnlyCarNLD/Datos/2.21. Data_Pipeline_Analytics]] |
| -------------------- | --------------------------------- |
| ⬅️ Hermano anterior  | [[Proyecto OnlyCarNLD/Datos/2.21.1 Estructura_Data_Warehouse]] |
| ➡️ Hermano siguiente | [[Proyecto OnlyCarNLD/Datos/2.21.3 Privacidad_Anonimizacion]] |

---
